train = {}
train_df = pd.DataFrame.from_dict(train.values())
train_df.index = train.keys()
train_df

def normalize(images, labels):
  images = tf.cast(images, tf.float32)
  images /= 255
  return images, labels

base_dir=f'_'
# Data augmentation
train_dir = f"{base_dir}/train"
test_dir = f"{base_dir}/test"
train_datagen = ImageDataGenerator(width_shift_range = 0.1,
                                    height_shift_range = 0.1,
                                    horizontal_flip = True,
                                   rescale = 1./255,
                                    #zoom_range = 0.2,
                                    rotation_range= 5, 
                                    shear_range= 0.2,
                                   fill_mode = 'nearest'
                                    )
test_datagen = ImageDataGenerator(rescale= 1.0/255)

train_generator = train_datagen.flow_from_directory(
                        train_dir,
                        target_size=(48,48),
                        batch_size=64,
                        color_mode = "grayscale",
                        class_mode='categorical',
                        subset = "training")

test_generator = test_datagen.flow_from_directory(
                        test_dir,
                        target_size=(48,48),
                        batch_size=64,
                        color_mode = "grayscale",
                        class_mode='categorical')

model = Sequential()
initializer = tf.keras.initializers.GlorotNormal()
x=(48,48,1)

# layer-1
model.add(Conv2D(128, (3, 3), padding='same', activation='relu', input_shape=x))
model.add(MaxPooling2D((2, 2), strides=2))
model.add(Dropout(0.5))
model.add(Dense(128, kernel_initializer = 'glorot_uniform'))

# layer-2
model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))
model.add(MaxPooling2D((2, 2), strides=2))
model.add(Dropout(0.5))
model.add(Dense(64, kernel_initializer = 'glorot_uniform'))

# layer-3
model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))
model.add(MaxPooling2D((2, 2), strides=2))
model.add(Dropout(0.5))


# output layer
model.add(Dense(32, kernel_initializer = 'glorot_uniform'))
model.add(Flatten())
model.add(Dense(7, activation = 'softmax'))

# Compile model
model.compile(
    loss='categorical_crossentropy',
    optimizer='adam',
    metrics=['accuracy']
)

gpu_info = !nvidia-smi
gpu_info = '\n'.join(gpu_info)
if gpu_info.find('failed') >= 0:
  print('Select the Runtime > "Change runtime type" menu to enable a GPU accelerator, ')
  print('and then re-execute this cell.')
else:
  print(gpu_info)
model.summary()
print (model.output_shape)

from tensorflow.keras.metrics import AUC, BinaryAccuracy, Precision, Recall
metric = [BinaryAccuracy(name = 'accuracy'), 
           Precision(name = 'precision'), 
           Recall(name = 'recall'), 
           AUC(name = 'AUC'),
           ]


model = tf.keras.models.load_model( f'_', custom_objects=None, compile=True, options=None)
history = model.fit_generator(train_generator, validation_data=test_generator,epochs=20,verbose = 1, shuffle = True)
model.save('/content/drive/MyDrive/Colab Notebooks/model-20210719-2300.h5')
#model.save_weights('model_weights.h5')
plt.figure(0)
plt.plot(history.history['accuracy'], label= 'train accuracy')
plt.plot(history.history['val_accuracy'], label= 'test accuracy')
plt.title('Accuracy')
plt.xlabel('epochs')
plt.ylabel('Accuracy')
plt.legend()
